{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils import data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self,\n",
    "                 src_voc_size=9000,\n",
    "                 trg_voc_size=9000,\n",
    "                 src_embedding_size=256,\n",
    "                 trg_embedding_size=256,\n",
    "                 enc_hidden_size=200,\n",
    "                 dec_hidden_size=200):\n",
    "        \n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.trg_embedding_size = trg_embedding_size\n",
    "        self.dec_hidden_size = dec_hidden_size\n",
    "        \n",
    "        self.src_embedder = nn.Embedding(src_voc_size , src_embedding_size)\n",
    "        self.encoder = nn.LSTM(src_embedding_size ,enc_hidden_size,3, batch_first=True,dropout=0.5)\n",
    "        \n",
    "        self.trg_embedder = nn.Embedding(trg_voc_size , trg_embedding_size)\n",
    "        self.decoder = nn.LSTM(trg_embedding_size ,dec_hidden_size,3, batch_first=True,dropout=0.5)\n",
    "        self.cls = nn.Linear(dec_hidden_size , trg_voc_size)\n",
    "    \n",
    "    def forward(self,source,target,feed_previous=False):\n",
    "        batch_size = source.size()[0]\n",
    "        src_em = self.src_embedder(source)\n",
    "        trg_em = self.trg_embedder(target)\n",
    "        \n",
    "        _ , enc_state = self.encoder(src_em)\n",
    "        \n",
    "        GO = Variable(torch.zeros(batch_size,1,self.trg_embedding_size))\n",
    "        \n",
    "        if feed_previous: #test phase\n",
    "            logits_ = []\n",
    "            inputs = GO\n",
    "            h = enc_state\n",
    "            for i in range(25):\n",
    "                output , h = self.decoder(inputs,h)\n",
    "                logits = self.cls(output.view(-1, self.dec_hidden_size))  # (1, vocab_size)\n",
    "                logits_.append(logits)\n",
    "                \n",
    "                predicted = logits.max(1)[1]\n",
    "                inputs = self.trg_embedder(predicted)\n",
    "                    \n",
    "            return torch.cat(logits_,0)\n",
    "            \n",
    "        else: #train phase\n",
    "            dec_in = torch.cat([GO,trg_em[:,:-1,:]],1)\n",
    "            outputs , _ = self.decoder(dec_in,enc_state)\n",
    "            outputs = outputs.contiguous().view(-1,self.dec_hidden_size)\n",
    "            logits = self.cls(outputs)\n",
    "        \n",
    "            return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "female = Seq2Seq()\n",
    "male = Seq2Seq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "female.load_state_dict(torch.load('model_female_cpu.pth'))\n",
    "male.load_state_dict(torch.load('model_male_cpu.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "female_sche = Seq2Seq()\n",
    "female_sche.load_state_dict(torch.load('model_female_sche_samplling_cpu.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "    def __init__(self,idx2word,word2idx):\n",
    "        self.idx2word = idx2word\n",
    "        self.word2idx = word2idx\n",
    "        self.max_len = 25\n",
    "        self.eos_idx = 8002\n",
    "        self.EN_WHITELIST  = '0123456789abcdefghijklmnopqrstuvwxyz '             \n",
    "            \n",
    "    '''\n",
    "    idx -> word with EOS\n",
    "    '''        \n",
    "    def decode_line(self,sentence_idx,remove_pad=True,remove_eos=True):  #sentence_idx: 1d_matrix     \n",
    "        sentence = []\n",
    "        for w in sentence_idx:\n",
    "            if remove_eos and w==self.eos_idx:\n",
    "                continue\n",
    "            if remove_pad and w==0 : \n",
    "                continue\n",
    "            sentence.append(self.idx2word[w])\n",
    "            #if w==self.eos_idx:\n",
    "            #    break\n",
    "        sentence = ' '.join(sentence)\n",
    "        return sentence\n",
    "    \n",
    "    def decode(self,sentence_idxs,remove_pad=True,remove_eos=True): #sentence_idxs: 2d_matrix \n",
    "        sentences = []\n",
    "        for s in sentence_idxs: \n",
    "            sentences.append(self.decode_line(s,\n",
    "                                              remove_pad=remove_pad,\n",
    "                                              remove_eos=remove_eos))\n",
    "        return sentences\n",
    "            \n",
    "    '''\n",
    "    word -> idx with EOS\n",
    "    '''\n",
    "    def encode_line(self,sentence):  #sentence: 1d_matrix\n",
    "        sentence = sentence.lower()\n",
    "        s_list = ''.join([ ch for ch in sentence if ch in self.EN_WHITELIST ]).split()\n",
    "        sentence_idx = []\n",
    "        for w in s_list:\n",
    "            sentence_idx.append(self.word2idx[w])\n",
    "        n = len(sentence_idx)\n",
    "        if  n > self.max_len:\n",
    "            sentence_idx = sentence_idx[:self.max_len] \n",
    "        elif n < self.max_len:\n",
    "            sentence_idx = sentence_idx + [self.eos_idx] + [0]*(self.max_len-n-1)  \n",
    "        return sentence_idx\n",
    "    \n",
    "    def encode(self,sentences): #sentences: 2d_matrix   \n",
    "        sentence_idxs = []\n",
    "        for s in sentences: \n",
    "            sentence_idxs.append(self.encode_line(s))\n",
    "        return np.array(sentence_idxs)\n",
    "    \n",
    "    def print_QA(self, ques , pred_ans, strd_ans):\n",
    "        n = len(ques)\n",
    "        for i in range(n):\n",
    "            idxs = [ ques[i],  pred_ans[i] , strd_ans[i]]\n",
    "            sents = vocab.decode(idxs,remove_eos=True,remove_pad=True)\n",
    "            print('\\nQ      :'+sents[0])  \n",
    "            print('A      :'+sents[2])\n",
    "            print('pred A :'+sents[1]) \n",
    "            \n",
    "    def print_QA_1(self, ques , pred_ans_train, pred_ans_test, strd_ans):\n",
    "        n = len(ques)\n",
    "        for i in range(n):\n",
    "            idxs = [ ques[i],  pred_ans_train[i], pred_ans_test[i] , strd_ans[i]]\n",
    "            sents = vocab.decode(idxs,remove_eos=True,remove_pad=True)\n",
    "            print('\\nQ      :'+sents[0])  \n",
    "            print('A      :'+sents[3])\n",
    "            print('train A:'+sents[1])    \n",
    "            print('test A :'+sents[2]) \n",
    "            \n",
    "    def print_QA_2(self, ques , ans):\n",
    "        n = len(ques)\n",
    "        for i in range(n):\n",
    "            idxs = [ ques[i], ans[i]]\n",
    "            sents = vocab.decode(idxs)\n",
    "            print('\\nQ      :'+sents[0])  \n",
    "            print('A      :'+sents[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('./metadata_1.pkl', 'rb') as f:\n",
    "        metadata = pickle.load(f)\n",
    "        \n",
    "vocab = Vocab(metadata['idx2w'] , metadata['w2idx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lines = []\n",
    "lines.append( 'you can do it'  )\n",
    "lines.append( 'how are you'    )\n",
    "lines.append( 'fuck you'  )\n",
    "lines.append( 'jesus christ you scared the shit out of me'  )\n",
    "lines.append( 'youre terrible'  )\n",
    "lines.append( 'is something wrong' )\n",
    "lines.append( 'nobodys gonna get inside' )\n",
    "lines.append( 'im sorry'  )\n",
    "lines.append( 'shut up'  )\n",
    "N = len(lines)\n",
    "lines = vocab.encode(lines)\n",
    "q_o = Variable(torch.from_numpy(lines).long())\n",
    "#vocab.decode(vocab.encode(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q      :you can do it\n",
      "A      :no i dont need maybe money i need to see you and i dont know why youre talking about the body\n",
      "\n",
      "Q      :how are you\n",
      "A      :im okay\n",
      "\n",
      "Q      :fuck you\n",
      "A      :fuck me fuck you\n",
      "\n",
      "Q      :jesus christ you scared the shit out of me\n",
      "A      :what things what do you mean\n",
      "\n",
      "Q      :youre terrible\n",
      "A      :i was just bunch about a word\n",
      "\n",
      "Q      :is something wrong\n",
      "A      :i want to be alone\n",
      "\n",
      "Q      :nobodys gonna get inside\n",
      "A      :thats beautiful\n",
      "\n",
      "Q      :im sorry\n",
      "A      :i thought you were saying you cant be a good mommy\n",
      "\n",
      "Q      :shut up\n",
      "A      :get out\n"
     ]
    }
   ],
   "source": [
    "female.eval()\n",
    "o = female(q_o,q_o,feed_previous=True)\n",
    "_,predict_o = o.max(1)\n",
    "#vocab.decode(predict_o.cpu().view(-1,3).data.numpy().T)\n",
    "pred_ans_o = predict_o.view(-1,N).data.numpy().T #predicted answer \n",
    "vocab.print_QA_2(lines, pred_ans_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q      :you can do it\n",
      "A      :its a good idea\n",
      "\n",
      "Q      :how are you\n",
      "A      :fine again you\n",
      "\n",
      "Q      :fuck you\n",
      "A      :i love you\n",
      "\n",
      "Q      :jesus christ you scared the shit out of me\n",
      "A      :you know what place of suit are graff\n",
      "\n",
      "Q      :youre terrible\n",
      "A      :im not control about the unk\n",
      "\n",
      "Q      :is something wrong\n",
      "A      :what is it\n",
      "\n",
      "Q      :nobodys gonna get inside\n",
      "A      :sure sir\n",
      "\n",
      "Q      :im sorry\n",
      "A      :what do you mean\n",
      "\n",
      "Q      :shut up\n",
      "A      :whos the dallas\n"
     ]
    }
   ],
   "source": [
    "male.eval()\n",
    "o = male(q_o,q_o,feed_previous=True)\n",
    "_,predict_o = o.max(1)\n",
    "#vocab.decode(predict_o.cpu().view(-1,3).data.numpy().T)\n",
    "pred_ans_o = predict_o.view(-1,N).data.numpy().T #predicted answer \n",
    "vocab.print_QA_2(lines, pred_ans_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q      :you can do it\n",
      "A      :yeah i know\n",
      "\n",
      "Q      :how are you\n",
      "A      :im fine\n",
      "\n",
      "Q      :fuck you\n",
      "A      :i cant help it michigan is a here\n",
      "\n",
      "Q      :jesus christ you scared the shit out of me\n",
      "A      :well its a nice kids thats a\n",
      "\n",
      "Q      :youre terrible\n",
      "A      :i know but i thought to you it i i you you you you you\n",
      "\n",
      "Q      :is something wrong\n",
      "A      :i know\n",
      "\n",
      "Q      :nobodys gonna get inside\n",
      "A      :i was unk to unk unk tries and meet her dumb\n",
      "\n",
      "Q      :im sorry\n",
      "A      :i know\n",
      "\n",
      "Q      :shut up\n",
      "A      :i have to find the and i didnt want to to be unk\n"
     ]
    }
   ],
   "source": [
    "female_sche.eval()\n",
    "o = female_sche(q_o,q_o,feed_previous=True)\n",
    "_,predict_o = o.max(1)\n",
    "#vocab.decode(predict_o.cpu().view(-1,3).data.numpy().T)\n",
    "pred_ans_o = predict_o.view(-1,N).data.numpy().T #predicted answer \n",
    "vocab.print_QA_2(lines, pred_ans_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def chat():\n",
    "    while 1:\n",
    "        #input_box\n",
    "        r = raw_input('Question:To whom{m,f,_}')\n",
    "        if ':' in r:\n",
    "            x,m= r.split(':')\n",
    "        else:\n",
    "            x,m = r,''\n",
    "        x,m = x.strip(), m.strip()\n",
    "        if x=='' :\n",
    "            break\n",
    "        \n",
    "        #decide model\n",
    "        if m == 'm':\n",
    "            model = male\n",
    "        elif m== 'f':\n",
    "            model = female\n",
    "        else:\n",
    "            model = female_sche\n",
    "        \n",
    "        #print answer\n",
    "        lines = []\n",
    "        lines.append( x )\n",
    "        N = len(lines)\n",
    "        lines = vocab.encode(lines)\n",
    "        q_o = Variable(torch.from_numpy(lines).long()) \n",
    "        o = model(q_o,q_o,feed_previous=True)\n",
    "        _,predict_o = o.max(1)\n",
    "        pred_ans_o = predict_o.view(-1,N).data.numpy().T #predicted answer \n",
    "        vocab.print_QA_2(lines, pred_ans_o)\n",
    "        print('')\n",
    "        \n",
    "    print('...end of conversation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def two_gender_chatting(characters=['m','f']):\n",
    "\n",
    "    \n",
    "    #input_box\n",
    "    r = raw_input('Srart conversation: ')\n",
    "    x = r\n",
    "    print('')\n",
    "\n",
    "    for i in range(3):   \n",
    "        for ch in characters: \n",
    "            #decide model\n",
    "            if ch == 'm':\n",
    "                model = male\n",
    "                ch = 'm     '\n",
    "            elif ch == 'f':\n",
    "                model = female\n",
    "                ch = 'f     '\n",
    "            else:\n",
    "                model = female_sche\n",
    "                ch = 'f_sche'\n",
    "                \n",
    "            lines = vocab.encode([x])\n",
    "            q_o = Variable(torch.from_numpy(lines).long()) \n",
    "            o = model(q_o,q_o,feed_previous=True)\n",
    "            _,predict_o = o.max(1)\n",
    "            pred_ans_o = predict_o.view(-1,1).data.numpy().T #predicted answer \n",
    "            x = vocab.decode(pred_ans_o)[0]\n",
    "            print(ch+' :'+x)   \n",
    "    \n",
    "    print('\\n...end of conversation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:To whom{m,f,_}hi : m\n",
      "\n",
      "Q      :hi\n",
      "A      :hey hey minor you look great\n",
      "\n",
      "Question:To whom{m,f,_}hi : f\n",
      "\n",
      "Q      :hi\n",
      "A      :thats good\n",
      "\n",
      "Question:To whom{m,f,_}hi :\n",
      "\n",
      "Q      :hi\n",
      "A      :hi hi\n",
      "\n",
      "Question:To whom{m,f,_}\n",
      "...end of conversation\n"
     ]
    }
   ],
   "source": [
    "chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Srart conversation: hi\n",
      "\n",
      "f_sche :hi hi\n",
      "f      :thats time\n",
      "f_sche :oh yeah\n",
      "f      :he didnt have anyone\n",
      "f_sche :no but he said hes unk\n",
      "f      :oh my god\n",
      "\n",
      "...end of conversation\n"
     ]
    }
   ],
   "source": [
    "two_gender_chatting(['f_s','f'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
