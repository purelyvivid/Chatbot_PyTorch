{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils import data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Data Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ans = np.load(\"./datasets/f_idx_a_1.npy\")\n",
    "ques = np.load(\"./datasets/f_idx_q_1.npy\")\n",
    "\n",
    "with open('./datasets/metadata_1.pkl', 'rb') as f:\n",
    "        metadata = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用torch的utils.data建立一來自numpy的dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FemaleDataset(data.Dataset): \n",
    "    def __init__(self,ques,ans):\n",
    "        self.ques = ques\n",
    "        self.ans = ans\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        ques_tensor = torch.from_numpy(self.ques[index]).long()\n",
    "        ans_tensor = torch.from_numpy(self.ans[index]).long()\n",
    "        \n",
    "        return ques_tensor , ans_tensor\n",
    "    \n",
    "    def __len__(self):\n",
    "        return 33589"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "將idx解析成文字"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "female_dataset = FemaleDataset(ques,ans)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=female_dataset,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self,\n",
    "                 src_voc_size=9000,\n",
    "                 trg_voc_size=9000,\n",
    "                 src_embedding_size=256,\n",
    "                 trg_embedding_size=256,\n",
    "                 enc_hidden_size=200,\n",
    "                 dec_hidden_size=200):\n",
    "        \n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.trg_embedding_size = trg_embedding_size\n",
    "        self.dec_hidden_size = dec_hidden_size\n",
    "        \n",
    "        self.src_embedder = nn.Embedding(src_voc_size , src_embedding_size)\n",
    "        self.encoder = nn.LSTM(src_embedding_size ,enc_hidden_size,3, batch_first=True,dropout=0.5)\n",
    "        \n",
    "        self.trg_embedder = nn.Embedding(trg_voc_size , trg_embedding_size)\n",
    "        self.decoder = nn.LSTM(trg_embedding_size ,dec_hidden_size,3, batch_first=True,dropout=0.5)\n",
    "        self.cls = nn.Linear(dec_hidden_size , trg_voc_size)\n",
    "    \n",
    "    def forward(self,source,target,feed_previous=False):\n",
    "        batch_size = source.size()[0]\n",
    "        src_em = self.src_embedder(source)\n",
    "        trg_em = self.trg_embedder(target)\n",
    "        \n",
    "        _ , enc_state = self.encoder(src_em)\n",
    "        \n",
    "        GO = Variable(torch.zeros(batch_size,1,self.trg_embedding_size)).cuda()\n",
    "        \n",
    "        if feed_previous: #test phase\n",
    "            logits_ = []\n",
    "            inputs = GO\n",
    "            h = enc_state\n",
    "            for i in range(25):\n",
    "                output , h = self.decoder(inputs,h)\n",
    "                logits = self.cls(output.view(-1, self.dec_hidden_size))  # (1, vocab_size)\n",
    "                logits_.append(logits)\n",
    "                \n",
    "                predicted = logits.max(1)[1]\n",
    "                inputs = self.trg_embedder(predicted)\n",
    "                    \n",
    "            return torch.cat(logits_,0)\n",
    "            \n",
    "        else: #train phase\n",
    "            dec_in = torch.cat([GO,trg_em[:,:-1,:]],1)\n",
    "            outputs , _ = self.decoder(dec_in,enc_state)\n",
    "            outputs = outputs.contiguous().view(-1,self.dec_hidden_size)\n",
    "            logits = self.cls(outputs)\n",
    "        \n",
    "            return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Seq2Seq().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq (\n",
       "  (src_embedder): Embedding(9000, 256)\n",
       "  (encoder): LSTM(256, 200, num_layers=3, batch_first=True, dropout=0.5)\n",
       "  (trg_embedder): Embedding(9000, 256)\n",
       "  (decoder): LSTM(256, 200, num_layers=3, batch_first=True, dropout=0.5)\n",
       "  (cls): Linear (200 -> 9000)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_op = optim.Adam(model.parameters() ,lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 , loss:2.3094009253\n",
      "epoch:10 , loss:1.66150550241\n",
      "epoch:20 , loss:1.53275449957\n",
      "epoch:30 , loss:1.4302389578\n",
      "epoch:40 , loss:1.33854958767\n",
      "epoch:50 , loss:1.25951292833\n",
      "epoch:60 , loss:1.1884868019\n",
      "epoch:70 , loss:1.12568164553\n",
      "epoch:80 , loss:1.06995315637\n",
      "epoch:90 , loss:1.02092015828\n",
      "epoch:100 , loss:0.975682859818\n",
      "epoch:110 , loss:0.933761150156\n",
      "epoch:120 , loss:0.897584251932\n",
      "epoch:130 , loss:0.863720377315\n",
      "epoch:140 , loss:0.832416369234\n",
      "epoch:150 , loss:0.804077076117\n",
      "epoch:160 , loss:0.777965487554\n",
      "epoch:170 , loss:0.754556149216\n",
      "epoch:180 , loss:0.731383187601\n",
      "epoch:190 , loss:0.710046492105\n",
      "epoch:199 , loss:0.692666306439\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "loss_hist = []\n",
    "loss_ = 3\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    epoch_mean_loss = []\n",
    "\n",
    "    for i , (q,a) in enumerate(train_loader):\n",
    "        q = Variable(q).cuda()\n",
    "        a = Variable(a).cuda()\n",
    "   \n",
    "        logits = model(q,a,feed_previous=False)\n",
    "        _,predict = logits.max(1)\n",
    "        \n",
    "        loss = F.cross_entropy(logits ,a.view(-1))\n",
    "        train_op.zero_grad()\n",
    "        loss.backward()\n",
    "        train_op.step()\n",
    "        \n",
    "        epoch_mean_loss.append(loss.data[0])\n",
    "    \n",
    "    loss_ = np.mean(epoch_mean_loss)\n",
    "    loss_hist.append(loss_)\n",
    "    if epoch % 10 == 0  or epoch == epochs-1:\n",
    "        print \"epoch:%s , loss:%s\" % (epoch , loss_ )\n",
    "    if epoch % 50 == 0 or epoch == epochs-1:\n",
    "        torch.save(model.state_dict() , 'pth/model_female_epo%s.pth'%epoch) #save model\n",
    "        \n",
    "np.save('loss_female_epo%s.npy'%epochs,loss_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_,predict = logits.max(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "    def __init__(self,idx2word,word2idx):\n",
    "        self.idx2word = idx2word\n",
    "        self.word2idx = word2idx\n",
    "        self.max_len = 25\n",
    "        self.eos_idx = 8002\n",
    "        self.EN_WHITELIST  = '0123456789abcdefghijklmnopqrstuvwxyz '             \n",
    "            \n",
    "    '''\n",
    "    idx -> word with EOS\n",
    "    '''        \n",
    "    def decode_line(self,sentence_idx,remove_pad=True,remove_eos=True):  #sentence_idx: 1d_matrix     \n",
    "        sentence = []\n",
    "        for w in sentence_idx:\n",
    "            if remove_eos and w==self.eos_idx:\n",
    "                continue\n",
    "            if remove_pad and w==0 : \n",
    "                continue\n",
    "            sentence.append(self.idx2word[w])\n",
    "            #if w==self.eos_idx:\n",
    "            #    break\n",
    "        sentence = ' '.join(sentence)\n",
    "        return sentence\n",
    "    \n",
    "    def decode(self,sentence_idxs,remove_pad=True,remove_eos=True): #sentence_idxs: 2d_matrix \n",
    "        sentences = []\n",
    "        for s in sentence_idxs: \n",
    "            sentences.append(self.decode_line(s,\n",
    "                                              remove_pad=remove_pad,\n",
    "                                              remove_eos=remove_eos))\n",
    "        return sentences\n",
    "            \n",
    "    '''\n",
    "    word -> idx with EOS\n",
    "    '''\n",
    "    def encode_line(self,sentence):  #sentence: 1d_matrix\n",
    "        sentence = sentence.lower()\n",
    "        s_list = ''.join([ ch for ch in sentence if ch in self.EN_WHITELIST ]).split()\n",
    "        sentence_idx = []\n",
    "        for w in s_list:\n",
    "            sentence_idx.append(self.word2idx[w])\n",
    "        n = len(sentence_idx)\n",
    "        if  n > self.max_len:\n",
    "            sentence_idx = sentence_idx[:self.max_len] \n",
    "        elif n < self.max_len:\n",
    "            sentence_idx = sentence_idx + [self.eos_idx] + [0]*(self.max_len-n-1)  \n",
    "        return sentence_idx\n",
    "    \n",
    "    def encode(self,sentences): #sentences: 2d_matrix   \n",
    "        sentence_idxs = []\n",
    "        for s in sentences: \n",
    "            sentence_idxs.append(self.encode_line(s))\n",
    "        return np.array(sentence_idxs)\n",
    "    \n",
    "    def print_QA(self, ques , pred_ans, strd_ans):\n",
    "        n = len(ques)\n",
    "        for i in range(n):\n",
    "            idxs = [ ques[i],  pred_ans[i] , strd_ans[i]]\n",
    "            sents = vocab.decode(idxs)\n",
    "            print('\\nQ      :'+sents[0])  \n",
    "            print('A      :'+sents[2])\n",
    "            print('pred A :'+sents[1]) \n",
    "            \n",
    "    def print_QA_1(self, ques , pred_ans_train, pred_ans_test, strd_ans):\n",
    "        n = len(ques)\n",
    "        for i in range(n):\n",
    "            idxs = [ ques[i],  pred_ans_train[i], pred_ans_test[i] , strd_ans[i]]\n",
    "            sents = vocab.decode(idxs)\n",
    "            print('\\nQ      :'+sents[0])  \n",
    "            print('A      :'+sents[3])\n",
    "            print('train A:'+sents[1])    \n",
    "            print('test A :'+sents[2]) \n",
    "            \n",
    "    def print_QA_2(self, ques , ans):\n",
    "        n = len(ques)\n",
    "        for i in range(n):\n",
    "            idxs = [ ques[i], ans[i]]\n",
    "            sents = vocab.decode(idxs)\n",
    "            print('\\nQ      :'+sents[0])  \n",
    "            print('A      :'+sents[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([525, 1])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 525/25\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab = Vocab(metadata['idx2w'] , metadata['w2idx'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try train corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q      :i lady me of like i you back\n",
      "A      :what about a if never are think\n",
      "pred A :why the the that a were jessica\n",
      "\n",
      "Q      :hate and out fine fruit alaska are that but\n",
      "A      :would you good hed heard good they her\n",
      "pred A :would you someday you heard so they you\n",
      "\n",
      "Q      :all then so norman loving it most itll feller\n",
      "A      :your classified one like one but told break\n",
      "pred A :you classified kind been that but told unk\n",
      "\n",
      "Q      :that i bad i you still to told\n",
      "A      :mother did oh a he her was\n",
      "pred A :mother you i a he her was\n",
      "\n",
      "Q      :phrase hole i i am left it be her\n",
      "A      :say you you honey cold said something bad\n",
      "pred A :say you you its anymore said what walking\n",
      "\n",
      "Q      :but it been erik i gone needs one about was\n",
      "A      :to roy anyone dont unk hed but could\n",
      "pred A :that got tell yes goodness hed was\n",
      "\n",
      "Q      :ill would so in mean fellas is unk of the he\n",
      "A      :that on from be or try might it you\n",
      "pred A :the me in or call might you you\n",
      "\n",
      "Q      :do be lonely a why what gone he us grudge\n",
      "A      :being feelings killer unk sam be cant do\n",
      "pred A :your feelings so im press be was say\n",
      "\n",
      "Q      :it an its describe are uwhou you\n",
      "A      :a but potato holiday a have me\n",
      "pred A :a but like holiday a be it\n",
      "\n",
      "Q      :on all all unk you be know the\n",
      "A      :object gate look following been a well\n",
      "pred A :object gate warn killed a well\n",
      "\n",
      "Q      :one right real for doing since i you guy\n",
      "A      :your how deputies i too beard he\n",
      "pred A :or where deputies i a beard she\n",
      "\n",
      "Q      :doctors life look gone i long dont must who\n",
      "A      :whole loser as do model can\n",
      "pred A :friend loser of guess model has\n",
      "\n",
      "Q      :that for the i theyll really alaska never dress\n",
      "A      :life wheres that much not cause just\n",
      "pred A :friend well what much not and say\n",
      "\n",
      "Q      :youre a fever said course love a unk you dancing\n",
      "A      :naked war break as do i fuck yeah\n",
      "pred A :naked god break as i fuck fuck\n",
      "\n",
      "Q      :there object digging another missed you force what of that up\n",
      "A      :james is mother it no works moment fuck\n",
      "pred A :sam is unk it no have tree fuck\n",
      "\n",
      "Q      :to for man the no to that design middle\n",
      "A      :you unk have for i to em\n",
      "pred A :i is its not to em\n",
      "\n",
      "Q      :give the was you show sometimes have is by\n",
      "A      :its can does you unless didnt her no\n",
      "pred A :its can is you the mean her now\n",
      "\n",
      "Q      :me average forgotten were i it not yourself and\n",
      "A      :okay get wont but know and terribly normal\n",
      "pred A :okay see wont i know and terribly the\n",
      "\n",
      "Q      :away in such say unk pray mr whats\n",
      "A      :boyfriend ten yall unk that what she dates\n",
      "pred A :boyfriend out yall as that what the dates\n",
      "\n",
      "Q      :his a okay do by my owned that\n",
      "A      :unk asking i whatd itll sure\n",
      "pred A :rush unk i clothes itll cant\n",
      "\n",
      "Q      :kind sandwich tourist certain you unless god sent\n",
      "A      :what on him have they didnt\n",
      "pred A :what here you never i knows\n"
     ]
    }
   ],
   "source": [
    "pred_ans = predict.cpu().view(-1,n).data.numpy().T #predicted answer in train phase\n",
    "strd_ans = a.cpu().view(-1,n).data.numpy().T #standard answer\n",
    "ques     = q.cpu().view(-1,n).data.numpy().T #quenstions\n",
    "vocab.print_QA(ques , pred_ans, strd_ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try test corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q      :i lady me of like i you back\n",
      "A      :what about a if never are think\n",
      "train A:why the the that a were jessica\n",
      "test A :what would you mean when you want\n",
      "\n",
      "Q      :hate and out fine fruit alaska are that but\n",
      "A      :would you good hed heard good they her\n",
      "train A:would you someday you heard so they you\n",
      "test A :you roy out on your class\n",
      "\n",
      "Q      :all then so norman loving it most itll feller\n",
      "A      :your classified one like one but told break\n",
      "train A:you classified kind been that but told unk\n",
      "test A :but gate\n",
      "\n",
      "Q      :that i bad i you still to told\n",
      "A      :mother did oh a he her was\n",
      "train A:mother you i a he her was\n",
      "test A :wheres war\n",
      "\n",
      "Q      :phrase hole i i am left it be her\n",
      "A      :say you you honey cold said something bad\n",
      "train A:say you you its anymore said what walking\n",
      "test A :its okay boyfriend\n",
      "\n",
      "Q      :but it been erik i gone needs one about was\n",
      "A      :to roy anyone dont unk hed but could\n",
      "train A:that got tell yes goodness hed was\n",
      "test A :what the hell did you kill me\n",
      "\n",
      "Q      :ill would so in mean fellas is unk of the he\n",
      "A      :that on from be or try might it you\n",
      "train A:the me in or call might you you\n",
      "test A :oh honey its just a good idea\n",
      "\n",
      "Q      :do be lonely a why what gone he us grudge\n",
      "A      :being feelings killer unk sam be cant do\n",
      "train A:your feelings so im press be was say\n",
      "test A :im a very nice skipped scared you both me\n",
      "\n",
      "Q      :it an its describe are uwhou you\n",
      "A      :a but potato holiday a have me\n",
      "train A:a but like holiday a be it\n",
      "test A :oh again you\n",
      "\n",
      "Q      :on all all unk you be know the\n",
      "A      :object gate look following been a well\n",
      "train A:object gate warn killed a well\n",
      "test A :its a good thing you can do for the unk of the finds\n",
      "\n",
      "Q      :one right real for doing since i you guy\n",
      "A      :your how deputies i too beard he\n",
      "train A:or where deputies i a beard she\n",
      "test A :i never told him anything i mike heard my breasts\n",
      "\n",
      "Q      :doctors life look gone i long dont must who\n",
      "A      :whole loser as do model can\n",
      "train A:friend loser of guess model has\n",
      "test A :but he said hed try\n",
      "\n",
      "Q      :that for the i theyll really alaska never dress\n",
      "A      :life wheres that much not cause just\n",
      "train A:friend well what much not and say\n",
      "test A :might be a good fuckin bag\n",
      "\n",
      "Q      :youre a fever said course love a unk you dancing\n",
      "A      :naked war break as do i fuck yeah\n",
      "train A:naked god break as i fuck fuck\n",
      "test A :i can see it\n",
      "\n",
      "Q      :there object digging another missed you force what of that up\n",
      "A      :james is mother it no works moment fuck\n",
      "train A:sam is unk it no have tree fuck\n",
      "test A :no i didnt know that\n",
      "\n",
      "Q      :to for man the no to that design middle\n",
      "A      :you unk have for i to em\n",
      "train A:i is its not to em\n",
      "test A :what itll\n",
      "\n",
      "Q      :give the was you show sometimes have is by\n",
      "A      :its can does you unless didnt her no\n",
      "train A:its can is you the mean her now\n",
      "test A :they told her that\n",
      "\n",
      "Q      :me average forgotten were i it not yourself and\n",
      "A      :okay get wont but know and terribly normal\n",
      "train A:okay see wont i know and terribly the\n",
      "test A :could you say anything to her like that\n",
      "\n",
      "Q      :away in such say unk pray mr whats\n",
      "A      :boyfriend ten yall unk that what she dates\n",
      "train A:boyfriend out yall as that what the dates\n",
      "test A :well shes at sweetheart shes a unk man but i wasnt there i was unk in the unk\n",
      "\n",
      "Q      :his a okay do by my owned that\n",
      "A      :unk asking i whatd itll sure\n",
      "train A:rush unk i clothes itll cant\n",
      "test A :fuck fuck lunch again you\n",
      "\n",
      "Q      :kind sandwich tourist certain you unless god sent\n",
      "A      :what on him have they didnt\n",
      "train A:what here you never i knows\n",
      "test A :wondering of lazy women youre the unk\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "o = model(q,a,feed_previous=True) #logits\n",
    "_,predict_test = o.max(1)\n",
    "#vocab.decode(predict_test.cpu().view(-1,10).data.numpy().T,remove_eos=False,remove_pad=False)\n",
    "pred_ans_test = predict_test.cpu().view(-1,n).data.numpy().T #predicted answer in test phase\n",
    "vocab.print_QA_1(ques , pred_ans, pred_ans_test, strd_ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try Chatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lines = []\n",
    "lines.append( 'you can do it'  )\n",
    "lines.append( 'how are you'    )\n",
    "lines.append( 'fuck you'  )\n",
    "lines.append( 'jesus christ you scared the shit out of me'  )\n",
    "lines.append( 'youre terrible'  )\n",
    "lines.append( 'is something wrong' )\n",
    "lines.append( 'nobodys gonna get inside' )\n",
    "lines.append( 'im sorry'  )\n",
    "lines.append( 'shut up'  )\n",
    "N = len(lines)\n",
    "lines = vocab.encode(lines)\n",
    "q_o = Variable(torch.from_numpy(lines).long()).cuda()\n",
    "#vocab.decode(vocab.encode(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q      :you can do it\n",
      "A      :no i dont need maybe money i need to see you and i dont know why youre talking about the body\n",
      "\n",
      "Q      :how are you\n",
      "A      :im okay\n",
      "\n",
      "Q      :fuck you\n",
      "A      :fuck me fuck you\n",
      "\n",
      "Q      :jesus christ you scared the shit out of me\n",
      "A      :what things what do you mean\n",
      "\n",
      "Q      :youre terrible\n",
      "A      :i was just bunch about a word\n",
      "\n",
      "Q      :is something wrong\n",
      "A      :i want to be alone\n",
      "\n",
      "Q      :nobodys gonna get inside\n",
      "A      :thats beautiful\n",
      "\n",
      "Q      :im sorry\n",
      "A      :i thought you were saying you cant be a good mommy\n",
      "\n",
      "Q      :shut up\n",
      "A      :get out\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "o = model(q_o,a[:N],feed_previous=True)\n",
    "_,predict_o = o.max(1)\n",
    "#vocab.decode(predict_o.cpu().view(-1,3).data.numpy().T)\n",
    "pred_ans_o = predict_o.cpu().view(-1,N).data.numpy().T #predicted answer \n",
    "vocab.print_QA_2(lines, pred_ans_o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#np.save('loss_female_prob_feed_epo141.npy',epoch_mean_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict() , 'model_female_prob_feed_epo141.pth') #save model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = Variable(torch.rand(3,25)*200).long()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_,p = model(x,q,feed_previous=True).max(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab.decode(p.view(3,25).data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
