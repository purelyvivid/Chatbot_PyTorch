{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "schedul sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils import data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Data Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ans = np.load(\"./datasets/f_idx_a_1.npy\")\n",
    "ques = np.load(\"./datasets/f_idx_q_1.npy\")\n",
    "\n",
    "with open('./datasets/metadata_1.pkl', 'rb') as f:\n",
    "        metadata = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用torch的utils.data建立一來自numpy的dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FemaleDataset(data.Dataset): \n",
    "    def __init__(self,ques,ans):\n",
    "        self.ques = ques\n",
    "        self.ans = ans\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        ques_tensor = torch.from_numpy(self.ques[index]).long()\n",
    "        ans_tensor = torch.from_numpy(self.ans[index]).long()\n",
    "        \n",
    "        return ques_tensor , ans_tensor\n",
    "    \n",
    "    def __len__(self):\n",
    "        return 33589"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "將idx解析成文字"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "female_dataset = FemaleDataset(ques,ans)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=female_dataset,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self,\n",
    "                 src_voc_size=9000,\n",
    "                 trg_voc_size=9000,\n",
    "                 src_embedding_size=256,\n",
    "                 trg_embedding_size=256,\n",
    "                 enc_hidden_size=200,\n",
    "                 dec_hidden_size=200):\n",
    "        \n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.trg_embedding_size = trg_embedding_size\n",
    "        self.dec_hidden_size = dec_hidden_size\n",
    "        \n",
    "        self.src_embedder = nn.Embedding(src_voc_size , src_embedding_size)\n",
    "        self.encoder = nn.LSTM(src_embedding_size ,enc_hidden_size,3, batch_first=True,dropout=0.5)\n",
    "        \n",
    "        self.trg_embedder = nn.Embedding(trg_voc_size , trg_embedding_size)\n",
    "        self.decoder = nn.LSTM(trg_embedding_size ,dec_hidden_size,3, batch_first=True,dropout=0.5)\n",
    "        self.cls = nn.Linear(dec_hidden_size , trg_voc_size)\n",
    "    \n",
    "    def forward(self,source,target,feed_previous=False):\n",
    "        batch_size = source.size()[0]\n",
    "        src_em = self.src_embedder(source)\n",
    "        trg_em = self.trg_embedder(target)\n",
    "        \n",
    "        _ , enc_state = self.encoder(src_em)\n",
    "        \n",
    "        GO = Variable(torch.zeros(batch_size,1,self.trg_embedding_size)).cuda()\n",
    "        \n",
    "        if feed_previous: #test phase\n",
    "            logits_ = []\n",
    "            inputs = GO\n",
    "            h = enc_state\n",
    "            for i in range(25):\n",
    "                output , h = self.decoder(inputs,h)\n",
    "                logits = self.cls(output.view(-1, self.dec_hidden_size))  # (1, vocab_size)\n",
    "                logits_.append(logits)\n",
    "                \n",
    "                predicted = logits.max(1)[1]\n",
    "                inputs = self.trg_embedder(predicted)\n",
    "                    \n",
    "            return torch.cat(logits_,0)\n",
    "            \n",
    "        else: #train phase -- schedule sampling\n",
    "            '''\n",
    "            dec_in = torch.cat([GO,trg_em[:,:-1,:]],1)  # trg_em.shape=(batch_size, time step, trg_embedding_size )\n",
    "            outputs , _ = self.decoder(dec_in,enc_state)\n",
    "            outputs = outputs.contiguous().view(-1,self.dec_hidden_size)\n",
    "            logits = self.cls(outputs)        \n",
    "            return logits  \n",
    "            '''\n",
    "            logits_ = []\n",
    "            dec_in = torch.cat([GO,trg_em[:,:-1,:]],1)\n",
    "            \n",
    "            h = enc_state\n",
    "            for i in range(25):\n",
    "                inputs = torch.unsqueeze(dec_in[:,i,:],1)\n",
    "                \n",
    "                if i < 5:\n",
    "                    inputs =  torch.unsqueeze(dec_in[:,i,:],1)\n",
    "                else:\n",
    "                    if random.random() < 0.5 : \n",
    "                        inputs =  torch.unsqueeze(dec_in[:,i,:],1)  #usual training policy \n",
    "                    else:\n",
    "                        inputs = self.trg_embedder(predicted)  #schedule sampling\n",
    "                \n",
    "                output , h = self.decoder(inputs,h)\n",
    "                logits = self.cls(output.view(-1, self.dec_hidden_size))  # (1, vocab_size)\n",
    "                logits_.append(logits)\n",
    "                predicted = logits.max(1)[1]  # predicted.shape=(batch_size, time step=1)\n",
    "                \n",
    "            return torch.cat(logits_,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Seq2Seq().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq (\n",
       "  (src_embedder): Embedding(9000, 256)\n",
       "  (encoder): LSTM(256, 200, num_layers=3, batch_first=True, dropout=0.5)\n",
       "  (trg_embedder): Embedding(9000, 256)\n",
       "  (decoder): LSTM(256, 200, num_layers=3, batch_first=True, dropout=0.5)\n",
       "  (cls): Linear (200 -> 9000)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_op = optim.Adam(model.parameters() ,lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 , loss:2.13266061488\n",
      "epoch:10 , loss:1.89427414065\n",
      "epoch:20 , loss:1.78954414686\n",
      "epoch:30 , loss:1.70985880046\n",
      "epoch:40 , loss:1.63794595003\n",
      "epoch:50 , loss:1.58399377034\n",
      "epoch:60 , loss:1.53486273612\n",
      "epoch:70 , loss:1.48763798061\n",
      "epoch:80 , loss:1.44421974727\n",
      "epoch:90 , loss:1.40060243976\n",
      "epoch:100 , loss:1.361112371\n",
      "epoch:110 , loss:1.3247071609\n",
      "epoch:120 , loss:1.28968011345\n",
      "epoch:130 , loss:1.25642937155\n",
      "epoch:140 , loss:1.22447708692\n",
      "epoch:150 , loss:1.19096727683\n",
      "epoch:160 , loss:1.16370675944\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-d1522ad03a54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_previous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-c8585161b851>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, source, target, feed_previous)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mtrg_em\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrg_embedder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0m_\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0menc_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_em\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mGO\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrg_embedding_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/modules/rnn.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mdropout_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         )\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/_functions/rnn.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, *fargs, **fkwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutogradRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/autograd/function.pyc\u001b[0m in \u001b[0;36m_do_forward\u001b[0;34m(self, *input)\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0mflat_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_iter_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0mflat_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNestedIOFunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mflat_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m         \u001b[0mnested_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0mnested_variables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/autograd/function.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0mnested_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_map_variable_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_extended\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/_functions/rnn.pyc\u001b[0m in \u001b[0;36mforward_extended\u001b[0;34m(self, input, weight, hx)\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0mhy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m         \u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_for_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/backends/cudnn/rnn.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(fn, input, hx, weight, output, hy)\u001b[0m\n\u001b[1;32m    294\u001b[0m                 \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcy_desc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_ptr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_ptr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreserve\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_ptr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreserve\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m             ))\n\u001b[1;32m    298\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "loss_hist = []\n",
    "loss_ = 3\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    epoch_mean_loss = []\n",
    "\n",
    "    for i , (q,a) in enumerate(train_loader):\n",
    "        q = Variable(q).cuda()\n",
    "        a = Variable(a).cuda()\n",
    "   \n",
    "        logits = model(q,a,feed_previous=False)\n",
    "        _,predict = logits.max(1)\n",
    "        \n",
    "        loss = F.cross_entropy(logits ,torch.transpose(a,0,1).contiguous().view(-1))\n",
    "        train_op.zero_grad()\n",
    "        loss.backward()\n",
    "        train_op.step()\n",
    "        \n",
    "        epoch_mean_loss.append(loss.data[0])\n",
    "    \n",
    "    loss_ = np.mean(epoch_mean_loss)\n",
    "    loss_hist.append(loss_)\n",
    "    if epoch % 10 == 0  or epoch == epochs-1:\n",
    "        print \"epoch:%s , loss:%s\" % (epoch , loss_ )\n",
    "    if epoch % 50 == 0 or epoch == epochs-1:\n",
    "        torch.save(model.state_dict() , 'pth/model_female_sche_sampling_epo%s.pth'%epoch) #save model\n",
    "        \n",
    "np.save('loss_female_sche_sampling_epo%s.npy'%epochs,loss_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_,predict = logits.max(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "    def __init__(self,idx2word,word2idx):\n",
    "        self.idx2word = idx2word\n",
    "        self.word2idx = word2idx\n",
    "        self.max_len = 25\n",
    "        self.eos_idx = 8002\n",
    "        self.EN_WHITELIST  = '0123456789abcdefghijklmnopqrstuvwxyz '             \n",
    "            \n",
    "    '''\n",
    "    idx -> word with EOS\n",
    "    '''        \n",
    "    def decode_line(self,sentence_idx,remove_pad=True,remove_eos=True):  #sentence_idx: 1d_matrix     \n",
    "        sentence = []\n",
    "        for w in sentence_idx:\n",
    "            if remove_eos and w==self.eos_idx:\n",
    "                continue\n",
    "            if remove_pad and w==0 : \n",
    "                continue\n",
    "            sentence.append(self.idx2word[w])\n",
    "            #if w==self.eos_idx:\n",
    "            #    break\n",
    "        sentence = ' '.join(sentence)\n",
    "        return sentence\n",
    "    \n",
    "    def decode(self,sentence_idxs,remove_pad=True,remove_eos=True): #sentence_idxs: 2d_matrix \n",
    "        sentences = []\n",
    "        for s in sentence_idxs: \n",
    "            sentences.append(self.decode_line(s,\n",
    "                                              remove_pad=remove_pad,\n",
    "                                              remove_eos=remove_eos))\n",
    "        return sentences\n",
    "            \n",
    "    '''\n",
    "    word -> idx with EOS\n",
    "    '''\n",
    "    def encode_line(self,sentence):  #sentence: 1d_matrix\n",
    "        sentence = sentence.lower()\n",
    "        s_list = ''.join([ ch for ch in sentence if ch in self.EN_WHITELIST ]).split()\n",
    "        sentence_idx = []\n",
    "        for w in s_list:\n",
    "            sentence_idx.append(self.word2idx[w])\n",
    "        n = len(sentence_idx)\n",
    "        if  n > self.max_len:\n",
    "            sentence_idx = sentence_idx[:self.max_len] \n",
    "        elif n < self.max_len:\n",
    "            sentence_idx = sentence_idx + [self.eos_idx] + [0]*(self.max_len-n-1)  \n",
    "        return sentence_idx\n",
    "    \n",
    "    def encode(self,sentences): #sentences: 2d_matrix   \n",
    "        sentence_idxs = []\n",
    "        for s in sentences: \n",
    "            sentence_idxs.append(self.encode_line(s))\n",
    "        return np.array(sentence_idxs)\n",
    "    \n",
    "    def print_QA(self, ques , pred_ans, strd_ans):\n",
    "        n = len(ques)\n",
    "        for i in range(n):\n",
    "            idxs = [ ques[i],  pred_ans[i] , strd_ans[i]]\n",
    "            sents = vocab.decode(idxs,remove_eos=True,remove_pad=True)\n",
    "            print('\\nQ      :'+sents[0])  \n",
    "            print('A      :'+sents[2])\n",
    "            print('pred A :'+sents[1]) \n",
    "            \n",
    "    def print_QA_1(self, ques , pred_ans_train, pred_ans_test, strd_ans):\n",
    "        n = len(ques)\n",
    "        for i in range(n):\n",
    "            idxs = [ ques[i],  pred_ans_train[i], pred_ans_test[i] , strd_ans[i]]\n",
    "            sents = vocab.decode(idxs,remove_eos=True,remove_pad=True)\n",
    "            print('\\nQ      :'+sents[0])  \n",
    "            print('A      :'+sents[3])\n",
    "            print('train A:'+sents[1])    \n",
    "            print('test A :'+sents[2]) \n",
    "            \n",
    "    def print_QA_2(self, ques , ans):\n",
    "        n = len(ques)\n",
    "        for i in range(n):\n",
    "            idxs = [ ques[i], ans[i]]\n",
    "            sents = vocab.decode(idxs)\n",
    "            print('\\nQ      :'+sents[0])  \n",
    "            print('A      :'+sents[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 800/25\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab = Vocab(metadata['idx2w'] , metadata['w2idx'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try train corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q      :hey thought i to dont something my it\n",
      "A      :i do even of live what crazy it theyre take\n",
      "pred A :i really not\n",
      "\n",
      "Q      :fool it care you hate you cotton has\n",
      "A      :together is want it are in i does unk off\n",
      "pred A :i said to halloween i i kronos was the awful i i i i i unk i was a unk to you\n",
      "\n",
      "Q      :this was about should you want well told a\n",
      "A      :it jack it you that know a unk call\n",
      "pred A :thanks i\n",
      "\n",
      "Q      :come sense that to okay me unk its\n",
      "A      :sort it sure house the shut no me\n",
      "pred A :schools moneys unk woman isnt a neither\n",
      "\n",
      "Q      :from it i do i i all him\n",
      "A      :other why would hes i hang honey if\n",
      "pred A :i dont not being disrespect woman\n",
      "\n",
      "Q      :did pretty about would would right\n",
      "A      :eat should look dead need seen free its you\n",
      "pred A :you you i\n",
      "\n",
      "Q      :not bound it like meet i\n",
      "A      :and i stupid to a right i the need\n",
      "pred A :no i i\n",
      "\n",
      "Q      :the with you somebody have what\n",
      "A      :theyve trust on know unk and was police anything the\n",
      "pred A :in keeping the unk and\n",
      "\n",
      "Q      :shell reaction that to whether a does\n",
      "A      :been you you applied what future wrong sent hello letters\n",
      "pred A :i know\n",
      "\n",
      "Q      :thats oh unk clever help name better it\n",
      "A      :married my happened then here value the\n",
      "pred A :thats not far apartment\n",
      "\n",
      "Q      :what no gun glad me roof headquarters i mean\n",
      "A      :for drink in call by yes one\n",
      "pred A :what it like it was to be\n",
      "\n",
      "Q      :what we flare is find with lets understand\n",
      "A      :twenty i will there me my i merle\n",
      "pred A :no they be to exploit that sold and the\n",
      "\n",
      "Q      :terrible call its you a unk a forget miss\n",
      "A      :years both you oh tomorrow country do wind\n",
      "pred A :what fine i eagle and me see\n",
      "\n",
      "Q      :seriously jeffrey the kings long ray jesus that that\n",
      "A      :a felt right well to mr of\n",
      "pred A :i know what wanted\n",
      "\n",
      "Q      :fast unk unk on time of george the you i\n",
      "A      :man are lucky unk how it\n",
      "pred A :i i knowing desire to the white emperor you only the unk and you you white is you engaged\n",
      "\n",
      "Q      :girl got hes a the fool ends have do\n",
      "A      :and youve you you will must\n",
      "pred A :and what you\n",
      "\n",
      "Q      :it no brilliant we unk that wont my not\n",
      "A      :his been what i be\n",
      "pred A :i know not i have to\n",
      "\n",
      "Q      :on good been today come method and son understand\n",
      "A      :500 telling if i do rich\n",
      "pred A :thats what thought it the unk time been\n",
      "\n",
      "Q      :oh her deliver down from i why in\n",
      "A      :i were me i cost this\n",
      "pred A :only faking\n",
      "\n",
      "Q      :hell own and what this i never do your\n",
      "A      :guess crawl what thats do you one\n",
      "pred A :i unk i i you want home\n",
      "\n",
      "Q      :i you did fifteen is have heard you safe\n",
      "A      :hours than not his its have\n",
      "pred A :all it\n",
      "\n",
      "Q      :dont know he i lamp a that say take\n",
      "A      :want mine to i unk that why\n",
      "pred A :and mean it\n",
      "\n",
      "Q      :know hello it say told there sleep you that it\n",
      "A      :wha hes do dont just nasty did\n",
      "pred A :again you\n",
      "\n",
      "Q      :ear baby you to i you this maam are easy\n",
      "A      :and intense four know theyre tell distress i\n",
      "pred A :what you want me talk to to\n",
      "\n",
      "Q      :to married you just how is by exhibit would\n",
      "A      :all me i his not me yes look have\n",
      "pred A :you becoming yourself\n",
      "\n",
      "Q      :you tom him in did it paul worry you you\n",
      "A      :why out into was unk england if i to\n",
      "pred A :oh that about\n",
      "\n",
      "Q      :everyones shes only do across can is who and are like\n",
      "A      :all here every old i twins theyre lamp would do\n",
      "pred A :so followed the similar\n",
      "\n",
      "Q      :have a still yourself you takes oh is now shelly a\n",
      "A      :my all result enough appreciate for alice really is this\n",
      "pred A :did have the unk dad\n",
      "\n",
      "Q      :to pretty i a make you my this im my san nasty\n",
      "A      :mom day prize to your me transmission thats there really to\n",
      "pred A :thats it did he mean\n",
      "\n",
      "Q      :talk costs well told secret them feel god fucking shelly of real\n",
      "A      :and long why on remember gay found places you worry\n",
      "pred A :i too like so\n",
      "\n",
      "Q      :to woman why you dont i do like toilet somebody my nice\n",
      "A      :dad do the im but no im dont jack\n",
      "pred A :no i you want adopt unk\n",
      "\n",
      "Q      :him bite do not ask sure england theres jerks unk painting\n",
      "A      :wont you crowd sick we matter not course think you\n",
      "pred A :you do i will you wont\n"
     ]
    }
   ],
   "source": [
    "pred_ans = predict.cpu().view(-1,n).data.numpy().T #predicted answer in train phase\n",
    "strd_ans = a.cpu().view(-1,n).data.numpy().T #standard answer\n",
    "ques     = q.cpu().view(-1,n).data.numpy().T #quenstions\n",
    "vocab.print_QA(ques , pred_ans, strd_ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try test corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q      :hey thought i to dont something my it\n",
      "A      :i do even of live what crazy it theyre take\n",
      "train A:i really not\n",
      "test A :i know what you mean\n",
      "\n",
      "Q      :fool it care you hate you cotton has\n",
      "A      :together is want it are in i does unk off\n",
      "train A:i said to halloween i i kronos was the awful i i i i i unk i was a unk to you\n",
      "test A :why do you want to to do me\n",
      "\n",
      "Q      :this was about should you want well told a\n",
      "A      :it jack it you that know a unk call\n",
      "train A:thanks i\n",
      "test A :i dont know\n",
      "\n",
      "Q      :come sense that to okay me unk its\n",
      "A      :sort it sure house the shut no me\n",
      "train A:schools moneys unk woman isnt a neither\n",
      "test A :a precious cheap\n",
      "\n",
      "Q      :from it i do i i all him\n",
      "A      :other why would hes i hang honey if\n",
      "train A:i dont not being disrespect woman\n",
      "test A :i dont know\n",
      "\n",
      "Q      :did pretty about would would right\n",
      "A      :eat should look dead need seen free its you\n",
      "train A:you you i\n",
      "test A :no you dont want to make poets credit unk unk you you you\n",
      "\n",
      "Q      :not bound it like meet i\n",
      "A      :and i stupid to a right i the need\n",
      "train A:no i i\n",
      "test A :hello bucks\n",
      "\n",
      "Q      :the with you somebody have what\n",
      "A      :theyve trust on know unk and was police anything the\n",
      "train A:in keeping the unk and\n",
      "test A :i know it was actually i i i i i you you to to to to know it\n",
      "\n",
      "Q      :shell reaction that to whether a does\n",
      "A      :been you you applied what future wrong sent hello letters\n",
      "train A:i know\n",
      "test A :applied my dad is given\n",
      "\n",
      "Q      :thats oh unk clever help name better it\n",
      "A      :married my happened then here value the\n",
      "train A:thats not far apartment\n",
      "test A :i dont know\n",
      "\n",
      "Q      :what no gun glad me roof headquarters i mean\n",
      "A      :for drink in call by yes one\n",
      "train A:what it like it was to be\n",
      "test A :youre not going to be with the and you you it you going to be you to\n",
      "\n",
      "Q      :what we flare is find with lets understand\n",
      "A      :twenty i will there me my i merle\n",
      "train A:no they be to exploit that sold and the\n",
      "test A :he said he wants to help me\n",
      "\n",
      "Q      :terrible call its you a unk a forget miss\n",
      "A      :years both you oh tomorrow country do wind\n",
      "train A:what fine i eagle and me see\n",
      "test A :oh god\n",
      "\n",
      "Q      :seriously jeffrey the kings long ray jesus that that\n",
      "A      :a felt right well to mr of\n",
      "train A:i know what wanted\n",
      "test A :unk unk unk\n",
      "\n",
      "Q      :fast unk unk on time of george the you i\n",
      "A      :man are lucky unk how it\n",
      "train A:i i knowing desire to the white emperor you only the unk and you you white is you engaged\n",
      "test A :i dont know i dont know i i dont want\n",
      "\n",
      "Q      :girl got hes a the fool ends have do\n",
      "A      :and youve you you will must\n",
      "train A:and what you\n",
      "test A :why not\n",
      "\n",
      "Q      :it no brilliant we unk that wont my not\n",
      "A      :his been what i be\n",
      "train A:i know not i have to\n",
      "test A :i dont think so\n",
      "\n",
      "Q      :on good been today come method and son understand\n",
      "A      :500 telling if i do rich\n",
      "train A:thats what thought it the unk time been\n",
      "test A :faithful come back back here\n",
      "\n",
      "Q      :oh her deliver down from i why in\n",
      "A      :i were me i cost this\n",
      "train A:only faking\n",
      "test A :unk unk\n",
      "\n",
      "Q      :hell own and what this i never do your\n",
      "A      :guess crawl what thats do you one\n",
      "train A:i unk i i you want home\n",
      "test A :what are you talking about\n",
      "\n",
      "Q      :i you did fifteen is have heard you safe\n",
      "A      :hours than not his its have\n",
      "train A:all it\n",
      "test A :is it unk hes so unk 60\n",
      "\n",
      "Q      :dont know he i lamp a that say take\n",
      "A      :want mine to i unk that why\n",
      "train A:and mean it\n",
      "test A :thats why i dont know what you is\n",
      "\n",
      "Q      :know hello it say told there sleep you that it\n",
      "A      :wha hes do dont just nasty did\n",
      "train A:again you\n",
      "test A :i dont know what to do with my mother\n",
      "\n",
      "Q      :ear baby you to i you this maam are easy\n",
      "A      :and intense four know theyre tell distress i\n",
      "train A:what you want me talk to to\n",
      "test A :oh yeah\n",
      "\n",
      "Q      :to married you just how is by exhibit would\n",
      "A      :all me i his not me yes look have\n",
      "train A:you becoming yourself\n",
      "test A :no again you\n",
      "\n",
      "Q      :you tom him in did it paul worry you you\n",
      "A      :why out into was unk england if i to\n",
      "train A:oh that about\n",
      "test A :i cost i dont know you to be\n",
      "\n",
      "Q      :everyones shes only do across can is who and are like\n",
      "A      :all here every old i twins theyre lamp would do\n",
      "train A:so followed the similar\n",
      "test A :yes i know\n",
      "\n",
      "Q      :have a still yourself you takes oh is now shelly a\n",
      "A      :my all result enough appreciate for alice really is this\n",
      "train A:did have the unk dad\n",
      "test A :oh no\n",
      "\n",
      "Q      :to pretty i a make you my this im my san nasty\n",
      "A      :mom day prize to your me transmission thats there really to\n",
      "train A:thats it did he mean\n",
      "test A :oh my god\n",
      "\n",
      "Q      :talk costs well told secret them feel god fucking shelly of real\n",
      "A      :and long why on remember gay found places you worry\n",
      "train A:i too like so\n",
      "test A :i mean you did that to me in it\n",
      "\n",
      "Q      :to woman why you dont i do like toilet somebody my nice\n",
      "A      :dad do the im but no im dont jack\n",
      "train A:no i you want adopt unk\n",
      "test A :i know\n",
      "\n",
      "Q      :him bite do not ask sure england theres jerks unk painting\n",
      "A      :wont you crowd sick we matter not course think you\n",
      "train A:you do i will you wont\n",
      "test A :it was a long time ago\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "o = model(q,a,feed_previous=True) #logits\n",
    "_,predict_test = o.max(1)\n",
    "#vocab.decode(predict_test.cpu().view(-1,10).data.numpy().T,remove_eos=False,remove_pad=False)\n",
    "pred_ans_test = predict_test.cpu().view(-1,n).data.numpy().T #predicted answer in test phase\n",
    "vocab.print_QA_1(ques , pred_ans, pred_ans_test, strd_ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try Chatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lines = []\n",
    "lines.append( 'you can do it'  )\n",
    "lines.append( 'how are you'    )\n",
    "lines.append( 'fuck you'  )\n",
    "lines.append( 'jesus christ you scared the shit out of me'  )\n",
    "lines.append( 'youre terrible'  )\n",
    "lines.append( 'is something wrong' )\n",
    "lines.append( 'nobodys gonna get inside' )\n",
    "lines.append( 'im sorry'  )\n",
    "lines.append( 'shut up'  )\n",
    "N = len(lines)\n",
    "lines = vocab.encode(lines)\n",
    "q_o = Variable(torch.from_numpy(lines).long()).cuda()\n",
    "#vocab.decode(vocab.encode(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q      :you can do it\n",
      "A      :yeah i know\n",
      "\n",
      "Q      :how are you\n",
      "A      :im fine\n",
      "\n",
      "Q      :fuck you\n",
      "A      :i cant help it michigan is a here\n",
      "\n",
      "Q      :jesus christ you scared the shit out of me\n",
      "A      :well its a nice kids thats a\n",
      "\n",
      "Q      :youre terrible\n",
      "A      :i know but i thought to you it i i you you you you you\n",
      "\n",
      "Q      :is something wrong\n",
      "A      :i know\n",
      "\n",
      "Q      :nobodys gonna get inside\n",
      "A      :i was unk to unk unk tries and meet her dumb\n",
      "\n",
      "Q      :im sorry\n",
      "A      :i know\n",
      "\n",
      "Q      :shut up\n",
      "A      :i have to find the and i didnt want to to be unk\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "o = model(q_o,q_o,feed_previous=True)\n",
    "_,predict_o = o.max(1)\n",
    "#vocab.decode(predict_o.cpu().view(-1,3).data.numpy().T)\n",
    "pred_ans_o = predict_o.cpu().view(-1,N).data.numpy().T #predicted answer \n",
    "vocab.print_QA_2(lines, pred_ans_o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict() , 'pth/model_female_sche_sampling_epo%s.pth'%epoch) #save model     \n",
    "np.save('loss_female_sche_sampling_epo%s.npy'%epochs,loss_hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = Variable(torch.rand(3,25)*200).long()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_,p = model(x,q,feed_previous=True).max(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab.decode(p.view(3,25).data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
