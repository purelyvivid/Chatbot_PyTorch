{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils import data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Data Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ans = np.load(\"./datasets/m_idx_a_1.npy\")\n",
    "ques = np.load(\"./datasets/m_idx_q_1.npy\")\n",
    "\n",
    "with open('./datasets/metadata_1.pkl', 'rb') as f:\n",
    "        metadata = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用torch的utils.data建立一來自numpy的dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MaleDataset(data.Dataset): \n",
    "    def __init__(self,ques,ans):\n",
    "        self.ques = ques\n",
    "        self.ans = ans\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        ques_tensor = torch.from_numpy(self.ques[index]).long()\n",
    "        ans_tensor = torch.from_numpy(self.ans[index]).long()\n",
    "        \n",
    "        return ques_tensor , ans_tensor\n",
    "    \n",
    "    def __len__(self):\n",
    "        return 78119"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "將idx解析成文字"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "male_dataset = MaleDataset(ques,ans)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=male_dataset,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self,\n",
    "                 src_voc_size=9000,\n",
    "                 trg_voc_size=9000,\n",
    "                 src_embedding_size=256,\n",
    "                 trg_embedding_size=256,\n",
    "                 enc_hidden_size=200,\n",
    "                 dec_hidden_size=200):\n",
    "        \n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.trg_embedding_size = trg_embedding_size\n",
    "        self.dec_hidden_size = dec_hidden_size\n",
    "        \n",
    "        self.src_embedder = nn.Embedding(src_voc_size , src_embedding_size)\n",
    "        self.encoder = nn.LSTM(src_embedding_size ,enc_hidden_size,3, batch_first=True,dropout=0.5)\n",
    "        \n",
    "        self.trg_embedder = nn.Embedding(trg_voc_size , trg_embedding_size)\n",
    "        self.decoder = nn.LSTM(trg_embedding_size ,dec_hidden_size,3, batch_first=True,dropout=0.5)\n",
    "        self.cls = nn.Linear(dec_hidden_size , trg_voc_size)\n",
    "    \n",
    "    def forward(self,source,target,feed_previous=False):\n",
    "        batch_size = source.size()[0]\n",
    "        src_em = self.src_embedder(source)\n",
    "        trg_em = self.trg_embedder(target)\n",
    "        \n",
    "        _ , enc_state = self.encoder(src_em)\n",
    "        \n",
    "        GO = Variable(torch.zeros(batch_size,1,self.trg_embedding_size)).cuda()\n",
    "        \n",
    "        if feed_previous: #test phase\n",
    "            logits_ = []\n",
    "            inputs = GO\n",
    "            h = enc_state\n",
    "            for i in range(25):\n",
    "                output , h = self.decoder(inputs,h)\n",
    "                logits = self.cls(output.view(-1, self.dec_hidden_size))  # (1, vocab_size)\n",
    "                logits_.append(logits)\n",
    "                \n",
    "                predicted = logits.max(1)[1]\n",
    "                inputs = self.trg_embedder(predicted)\n",
    "                    \n",
    "            return torch.cat(logits_,0)\n",
    "            \n",
    "        else: #train phase\n",
    "            dec_in = torch.cat([GO,trg_em[:,:-1,:]],1)\n",
    "            outputs , _ = self.decoder(dec_in,enc_state)\n",
    "            outputs = outputs.contiguous().view(-1,self.dec_hidden_size)\n",
    "            logits = self.cls(outputs)\n",
    "        \n",
    "            return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Seq2Seq().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq (\n",
       "  (src_embedder): Embedding(9000, 256)\n",
       "  (encoder): LSTM(256, 200, num_layers=3, batch_first=True, dropout=0.5)\n",
       "  (trg_embedder): Embedding(9000, 256)\n",
       "  (decoder): LSTM(256, 200, num_layers=3, batch_first=True, dropout=0.5)\n",
       "  (cls): Linear (200 -> 9000)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_op = optim.Adam(model.parameters() ,lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 , loss:2.1570013063\n",
      "epoch:10 , loss:1.65180309672\n",
      "epoch:20 , loss:1.54403085176\n",
      "epoch:30 , loss:1.46688195653\n",
      "epoch:40 , loss:1.40535816604\n",
      "epoch:50 , loss:1.35423740828\n",
      "epoch:60 , loss:1.31112265833\n",
      "epoch:70 , loss:1.27307238745\n",
      "epoch:80 , loss:1.2397340821\n",
      "epoch:90 , loss:1.2094951676\n",
      "epoch:100 , loss:1.18277289263\n",
      "epoch:110 , loss:1.15926431267\n",
      "epoch:120 , loss:1.13700090819\n",
      "epoch:130 , loss:1.11663240521\n",
      "epoch:140 , loss:1.09736820416\n",
      "epoch:150 , loss:1.08017611609\n",
      "epoch:160 , loss:1.06460089849\n",
      "epoch:170 , loss:1.04964912494\n",
      "epoch:180 , loss:1.03527451408\n",
      "epoch:190 , loss:1.02238349497\n",
      "epoch:199 , loss:1.01203030824\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "loss_hist = []\n",
    "loss_ = 3\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    epoch_mean_loss = []\n",
    "\n",
    "    for i , (q,a) in enumerate(train_loader):\n",
    "        q = Variable(q).cuda()\n",
    "        a = Variable(a).cuda()\n",
    "   \n",
    "        logits = model(q,a,feed_previous=False)\n",
    "        _,predict = logits.max(1)\n",
    "        \n",
    "        loss = F.cross_entropy(logits ,a.view(-1))\n",
    "        train_op.zero_grad()\n",
    "        loss.backward()\n",
    "        train_op.step()\n",
    "        \n",
    "        epoch_mean_loss.append(loss.data[0])\n",
    "    \n",
    "    loss_ = np.mean(epoch_mean_loss)\n",
    "    loss_hist.append(loss_)\n",
    "    if epoch % 10 == 0  or epoch == epochs-1:\n",
    "        print \"epoch:%s , loss:%s\" % (epoch , loss_ )\n",
    "    if epoch % 50 == 0 or epoch == epochs-1:\n",
    "        torch.save(model.state_dict() , 'pth/model_male_epo%s.pth'%epoch) #save model\n",
    "        \n",
    "np.save('loss_male_epo%s.npy'%epochs,loss_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_,predict = logits.max(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "    def __init__(self,idx2word,word2idx):\n",
    "        self.idx2word = idx2word\n",
    "        self.word2idx = word2idx\n",
    "        self.max_len = 25\n",
    "        self.eos_idx = 8002\n",
    "        self.EN_WHITELIST  = '0123456789abcdefghijklmnopqrstuvwxyz '             \n",
    "            \n",
    "    '''\n",
    "    idx -> word with EOS\n",
    "    '''        \n",
    "    def decode_line(self,sentence_idx,remove_pad=True,remove_eos=True):  #sentence_idx: 1d_matrix     \n",
    "        sentence = []\n",
    "        for w in sentence_idx:\n",
    "            if remove_eos and w==self.eos_idx:\n",
    "                continue\n",
    "            if remove_pad and w==0 : \n",
    "                continue\n",
    "            sentence.append(self.idx2word[w])\n",
    "            #if w==self.eos_idx:\n",
    "            #    break\n",
    "        sentence = ' '.join(sentence)\n",
    "        return sentence\n",
    "    \n",
    "    def decode(self,sentence_idxs,remove_pad=True,remove_eos=True): #sentence_idxs: 2d_matrix \n",
    "        sentences = []\n",
    "        for s in sentence_idxs: \n",
    "            sentences.append(self.decode_line(s,\n",
    "                                              remove_pad=remove_pad,\n",
    "                                              remove_eos=remove_eos))\n",
    "        return sentences\n",
    "            \n",
    "    '''\n",
    "    word -> idx with EOS\n",
    "    '''\n",
    "    def encode_line(self,sentence):  #sentence: 1d_matrix\n",
    "        sentence = sentence.lower()\n",
    "        s_list = ''.join([ ch for ch in sentence if ch in self.EN_WHITELIST ]).split()\n",
    "        sentence_idx = []\n",
    "        for w in s_list:\n",
    "            sentence_idx.append(self.word2idx[w])\n",
    "        n = len(sentence_idx)\n",
    "        if  n > self.max_len:\n",
    "            sentence_idx = sentence_idx[:self.max_len] \n",
    "        elif n < self.max_len:\n",
    "            sentence_idx = sentence_idx + [self.eos_idx] + [0]*(self.max_len-n-1)  \n",
    "        return sentence_idx\n",
    "    \n",
    "    def encode(self,sentences): #sentences: 2d_matrix   \n",
    "        sentence_idxs = []\n",
    "        for s in sentences: \n",
    "            sentence_idxs.append(self.encode_line(s))\n",
    "        return np.array(sentence_idxs)\n",
    "    \n",
    "    def print_QA(self, ques , pred_ans, strd_ans):\n",
    "        n = len(ques)\n",
    "        for i in range(n):\n",
    "            idxs = [ ques[i],  pred_ans[i] , strd_ans[i]]\n",
    "            sents = vocab.decode(idxs)\n",
    "            print('\\nQ      :'+sents[0])  \n",
    "            print('A      :'+sents[2])\n",
    "            print('pred A :'+sents[1]) \n",
    "            \n",
    "    def print_QA_1(self, ques , pred_ans_train, pred_ans_test, strd_ans):\n",
    "        n = len(ques)\n",
    "        for i in range(n):\n",
    "            idxs = [ ques[i],  pred_ans_train[i], pred_ans_test[i] , strd_ans[i]]\n",
    "            sents = vocab.decode(idxs)\n",
    "            print('\\nQ      :'+sents[0])  \n",
    "            print('A      :'+sents[3])\n",
    "            print('train A:'+sents[1])    \n",
    "            print('test A :'+sents[2]) \n",
    "            \n",
    "    def print_QA_2(self, ques , ans):\n",
    "        n = len(ques)\n",
    "        for i in range(n):\n",
    "            idxs = [ ques[i], ans[i]]\n",
    "            sents = vocab.decode(idxs)\n",
    "            print('\\nQ      :'+sents[0])  \n",
    "            print('A      :'+sents[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([175, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 175/25\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab = Vocab(metadata['idx2w'] , metadata['w2idx'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try train corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q      :why suggs as doctor i know\n",
      "A      :unk i another over i in but he you and eighteen\n",
      "pred A :hey i unk milk i in but he unk\n",
      "\n",
      "Q      :are what they was he\n",
      "A      :get cant theres one could a i did had my party\n",
      "pred A :unk really its one calvin a i was did navy of\n",
      "\n",
      "Q      :you is can mrs joe request\n",
      "A      :out million a unk get shock arthur had and to fucking\n",
      "pred A :out tell a charge say hey arthur dont something corner\n",
      "\n",
      "Q      :trouble it use unk planning shirt get\n",
      "A      :of you car us professor ok enough i at this watching\n",
      "pred A :of out unk to professor to he go wheres following\n",
      "\n",
      "Q      :this what you ready unk in\n",
      "A      :cannon you out empty the of be reason told least is and\n",
      "pred A :here you up unk with of ill unk didnt the is\n",
      "\n",
      "Q      :out river as and i there\n",
      "A      :know us next i this with to you rick my im\n",
      "pred A :know me unk i her gonna to you rick my\n",
      "\n",
      "Q      :on certainly long waiting when didnt\n",
      "A      :baby probably street pay thing you yeah believe so him vacation the\n",
      "pred A :i six didnt one you yeah hide hed it record going\n"
     ]
    }
   ],
   "source": [
    "pred_ans = predict.cpu().view(-1,n).data.numpy().T #predicted answer in train phase\n",
    "strd_ans = a.cpu().view(-1,n).data.numpy().T #standard answer\n",
    "ques     = q.cpu().view(-1,n).data.numpy().T #quenstions\n",
    "vocab.print_QA(ques , pred_ans, strd_ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try test corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q      :why suggs as doctor i know\n",
      "A      :unk i another over i in but he you and eighteen\n",
      "train A:hey i unk milk i in but he unk\n",
      "test A :unk unk\n",
      "\n",
      "Q      :are what they was he\n",
      "A      :get cant theres one could a i did had my party\n",
      "train A:unk really its one calvin a i was did navy of\n",
      "test A :you know i dont know what youre talking about\n",
      "\n",
      "Q      :you is can mrs joe request\n",
      "A      :out million a unk get shock arthur had and to fucking\n",
      "train A:out tell a charge say hey arthur dont something corner\n",
      "test A :its a unk\n",
      "\n",
      "Q      :trouble it use unk planning shirt get\n",
      "A      :of you car us professor ok enough i at this watching\n",
      "train A:of out unk to professor to he go wheres following\n",
      "test A :oh i message i was just asking exchange\n",
      "\n",
      "Q      :this what you ready unk in\n",
      "A      :cannon you out empty the of be reason told least is and\n",
      "train A:here you up unk with of ill unk didnt the is\n",
      "test A :hey okay\n",
      "\n",
      "Q      :out river as and i there\n",
      "A      :know us next i this with to you rick my im\n",
      "train A:know me unk i her gonna to you rick my\n",
      "test A :yeah but he was in the soup\n",
      "\n",
      "Q      :on certainly long waiting when didnt\n",
      "A      :baby probably street pay thing you yeah believe so him vacation the\n",
      "train A:i six didnt one you yeah hide hed it record going\n",
      "test A :wheres your car\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "o = model(q,a,feed_previous=True) #logits\n",
    "_,predict_test = o.max(1)\n",
    "#vocab.decode(predict_test.cpu().view(-1,10).data.numpy().T,remove_eos=False,remove_pad=False)\n",
    "pred_ans_test = predict_test.cpu().view(-1,n).data.numpy().T #predicted answer in test phase\n",
    "vocab.print_QA_1(ques , pred_ans, pred_ans_test, strd_ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try Chatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lines = []\n",
    "lines.append( 'you can do it'  )\n",
    "lines.append( 'how are you'    )\n",
    "lines.append( 'fuck you'  )\n",
    "lines.append( 'jesus christ you scared the shit out of me'  )\n",
    "lines.append( 'youre terrible'  )\n",
    "lines.append( 'is something wrong' )\n",
    "lines.append( 'nobodys gonna get inside' )\n",
    "lines.append( 'im sorry'  )\n",
    "lines.append( 'shut up'  )\n",
    "N = len(lines)\n",
    "lines = vocab.encode(lines)\n",
    "q_o = Variable(torch.from_numpy(lines).long()).cuda()\n",
    "#vocab.decode(vocab.encode(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q      :you can do it\n",
      "A      :its a good idea\n",
      "\n",
      "Q      :how are you\n",
      "A      :fine again you\n",
      "\n",
      "Q      :fuck you\n",
      "A      :i love you\n",
      "\n",
      "Q      :jesus christ you scared the shit out of me\n",
      "A      :you know what place of suit are graff\n",
      "\n",
      "Q      :youre terrible\n",
      "A      :im not control about the unk\n",
      "\n",
      "Q      :is something wrong\n",
      "A      :what is it\n",
      "\n",
      "Q      :nobodys gonna get inside\n",
      "A      :sure sir\n",
      "\n",
      "Q      :im sorry\n",
      "A      :what do you mean\n",
      "\n",
      "Q      :shut up\n",
      "A      :whos the dallas\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "o = model(q_o,a[:N],feed_previous=True)\n",
    "_,predict_o = o.max(1)\n",
    "#vocab.decode(predict_o.cpu().view(-1,3).data.numpy().T)\n",
    "pred_ans_o = predict_o.cpu().view(-1,N).data.numpy().T #predicted answer \n",
    "vocab.print_QA_2(lines, pred_ans_o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#np.save('loss_female_prob_feed_epo141.npy',epoch_mean_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict() , 'model_female_prob_feed_epo141.pth') #save model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = Variable(torch.rand(3,25)*200).long()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_,p = model(x,q,feed_previous=True).max(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab.decode(p.view(3,25).data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
